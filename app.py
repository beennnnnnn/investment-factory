import streamlit as st
import google.generativeai as genai
import feedparser
from newspaper import Article
import urllib.parse
import re

# --- 1. UI ì„¤ì • ---
st.set_page_config(page_title="ë¨¸ìŠ¤í¬ë…¸ë¯¸ ë© (Muskonomy Lab)", layout="wide", page_icon="ğŸš€")
st.title("ğŸš€ ë¨¸ìŠ¤í¬ë…¸ë¯¸ ë© (Muskonomy Lab)")
st.caption("ğŸ“± ë°ì´í„° ê¸°ë°˜ì˜ ì •êµí•œ ë¶„ì„ ë¦¬í¬íŠ¸ ê³µì¥")

# --- 2. ì‚¬ì´ë“œë°”: ê²€ìƒ‰ì–´ ìµœì í™” (ê²€ìƒ‰ ì„±ê³µë¥ ì„ ìœ„í•´ í‚¤ì›Œë“œ ë‹¨ì¶•) ---
with st.sidebar:
    st.header("ğŸ”‘ ë³´ì•ˆ ì„¸ì…˜")
    user_api_key = st.text_input("Gemini API í‚¤ ì…ë ¥:", type="password")
    
    st.divider()
    st.header("âš™ï¸ ì •ë³´ ìˆ˜ì§‘ ì„¤ì •")
    
    # [ìˆ˜ì •] ê²€ìƒ‰ì´ ì˜ ë˜ë„ë¡ í‚¤ì›Œë“œë¥¼ í•µì‹¬ ì¢…ëª©ëª… ìœ„ì£¼ë¡œ ì§§ê²Œ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤.
    DEFAULT_THEMES = {
        "ğŸ‡°ğŸ‡· êµ­ì¥ ì‹œí™© (ì½”ìŠ¤í”¼/ì½”ìŠ¤ë‹¥)": "ì½”ìŠ¤í”¼ ì½”ìŠ¤ë‹¥ ì‹œí™©",
        "ğŸŒ ê±°ì‹œê²½ì œ (í™˜ìœ¨/ê¸ˆë¦¬)": "í™˜ìœ¨ ê¸ˆë¦¬ ì „ë§",
        "ğŸ’¾ ë°˜ë„ì²´ (ì‚¼ì„±/SK/í•œë¯¸)": "ì‚¼ì„±ì „ì SKí•˜ì´ë‹‰ìŠ¤ í•œë¯¸ë°˜ë„ì²´",
        "ğŸ”‹ 2ì°¨ì „ì§€ (SDI/ì—ì½”í”„ë¡œ)": "ì‚¼ì„±SDI ì—ì½”í”„ë¡œ ì—ì½”í”„ë¡œë¹„ì— ",
        "ğŸš— ëª¨ë¹Œë¦¬í‹° (í˜„ëŒ€ì°¨/ë§Œë„)": "í˜„ëŒ€ì°¨ HLë§Œë„",
        "ğŸ¤– ë¡œë´‡ (ë ˆì¸ë³´ìš°)": "ë ˆì¸ë³´ìš°ë¡œë³´í‹±ìŠ¤ ë¡œë´‡",
        "ğŸš€ ë°©ì‚°/ìš°ì£¼ (í•œí™”ì—ì–´ë¡œ)": "í•œí™”ì—ì–´ë¡œìŠ¤í˜ì´ìŠ¤ ë°©ì‚°",
        "âš¡ ì¤‘ê³µì—… (íš¨ì„±ì¤‘ê³µì—…)": "íš¨ì„±ì¤‘ê³µì—… ì „ë ¥",
        "ğŸ§  ë¨¸ìŠ¤í¬ë…¸ë¯¸ (Tesla/xAI)": "Tesla xAI Elon Musk",
        "ğŸ“ˆ ë‚˜ìŠ¤ë‹¥/ë¯¸ì¥ ì‹œí™©": "Nasdaq 100 stock",
        "â‚¿ ë¹„íŠ¸ì½”ì¸/ì½”ì¸": "Bitcoin crypto news",
        "â• ì§ì ‘ ì…ë ¥": "custom"
    }
    
    selected_theme = st.selectbox("ë¶„ì„ ì£¼ì œ ì„ íƒ:", list(DEFAULT_THEMES.keys()))
    search_keyword = st.text_input("ê²€ìƒ‰ì–´:") if selected_theme == "â• ì§ì ‘ ì…ë ¥" else DEFAULT_THEMES[selected_theme]
    news_count = st.slider("êµ­ê°€ë³„ ì°¸ê³  ë‰´ìŠ¤ ê°œìˆ˜", 1, 5, 3)

# --- 3. ë¬¸ì²´ ìŠ¤íƒ€ì¼ ê°€ì´ë“œ ---
PRESET_STYLES = {
    "ğŸŒŒ ë¡œì¼“í…ŒìŠ¬ë¼ ìŠ¤íƒ€ì¼ (@rklb_invest)": "ë…¼ë¦¬ì  ì¸ê³¼ê´€ê³„ë¥¼ ì¤‘ì‹œí•˜ëŠ” ì „ëµì  ìŠ¤í† ë¦¬í…”ë§. 'ìš°ì—°ì€ ì—†ë‹¤, ì˜ë„ë§Œ ì¡´ì¬í•  ë¿'ì´ë¼ëŠ” ë¬¸êµ¬ë¥¼ ë„ì…ë¶€ì— í™œìš©í•˜ë©°, ê¹Šì´ ìˆëŠ” íƒ€ë˜ í˜•ì‹ì„ ì„ í˜¸í•¨.",
    "â˜€ï¸ ë¯¸êµ­ê°œë¯¸ ìŠ¤íƒ€ì¼ (@USAnt_IDEA)": "ì—´ì •ì ì´ê³  ì¹œì ˆí•œ ë©˜í† ë§. í•µì‹¬ ë°ì´í„°ë¥¼ ëª…í™•í•˜ê²Œ ì§šì–´ì£¼ë©° ë…ìë“¤ì„ ì‘ì›í•˜ëŠ” ê¸ì •ì ì¸ í†¤. ë§ˆë¬´ë¦¬ ë¬¸êµ¬ 'Powered by #USAnt' ê³ ìˆ˜.",
    "ğŸ’ ë°˜ë³´ ìŠ¤íƒ€ì¼ (@Banbo_Insight)": "ë¹„ìœ ì™€ ì˜ˆì‹œë¥¼ í™œìš©í•œ ë‹¤ì •í•˜ê³  ì‰¬ìš´ ì„¤ëª…. [ì œëª©] í˜•ì‹ì„ ë°˜ë“œì‹œ ì‚¬ìš©í•˜ê³  ë²ˆí˜¸ë¥¼ ë§¤ê²¨ ì •ë³´ë¥¼ êµ¬ì¡°í™”í•¨.",
    "â• ì§ì ‘ ìŠ¤íƒ€ì¼ ì—…ë¡œë“œ": "custom"
}

st.subheader("âœï¸ ë¶„ì„ í˜ë¥´ì†Œë‚˜ ì„ íƒ")
selected_style_key = st.selectbox("ëˆ„êµ¬ì˜ ë¬¸ì²´ë¡œ ë¶„ì„í• ê¹Œìš”?", list(PRESET_STYLES.keys()))
style_content = PRESET_STYLES[selected_style_key]

# --- 4. ë‰´ìŠ¤ ìˆ˜ì§‘ í•¨ìˆ˜ ---
def fetch_global_news(keyword, lang, geo, count):
    encoded_q = urllib.parse.quote(keyword)
    url = f"https://news.google.com/rss/search?q={encoded_q}&hl={lang}&gl={geo}&ceid={geo}:{lang}"
    feed = feedparser.parse(url)
    results = []
    for entry in feed.entries[:count]:
        try:
            article = Article(entry.link)
            article.download(); article.parse()
            if len(article.text) > 200: # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ì€ ê´‘ê³ ì„± ë§í¬ ì œì™¸
                results.append({"title": entry.title, "link": entry.link, "image": article.top_image, "text": article.text[:1200]})
        except: continue
    return results

# --- 5. ì‹¤í–‰ ë¡œì§ ---
if st.button("ğŸš€ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘"):
    if not user_api_key or not search_keyword:
        st.error("API í‚¤ì™€ ì£¼ì œë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.")
    else:
        try:
            genai.configure(api_key=user_api_key)
            model = genai.GenerativeModel('gemini-flash-latest')
            
            with st.spinner("ë°ì´í„° ìˆ˜ì§‘ ë° ë²ˆì—­ ì¤‘..."):
                # ë¯¸êµ­ ë‰´ìŠ¤ìš© ê²€ìƒ‰ì–´ ë²ˆì—­
                us_keyword = model.generate_content(f"Translate '{search_keyword}' to a short English news search keyword. Keyword only.").text.strip()
                
                kr_news = fetch_global_news(search_keyword, "ko", "KR", news_count)
                us_news = fetch_global_news(us_keyword, "en", "US", news_count)
                all_news = kr_news + us_news

            if not all_news:
                st.warning(f"'{search_keyword}'ì— ëŒ€í•œ ìµœì‹  ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²€ìƒ‰ì–´ë¥¼ ë” ì§§ê²Œ ìˆ˜ì •í•´ ë³´ì„¸ìš”.")
            else:
                # ì‹œê°í™”
                st.subheader("ğŸ“° ë¶„ì„ ë°ì´í„° ì›ë³¸")
                cols = st.columns(3)
                for idx, news in enumerate(all_news):
                    with cols[idx % 3]:
                        if news['image']: st.image(news['image'], use_container_width=True)
                        st.markdown(f"**[{news['title']}]({news['link']})**")
                
                with st.spinner("ë¦¬í¬íŠ¸ ì‘ì„± ì¤‘..."):
                    context = "\n".join([f"ê¸°ì‚¬ì œëª©: {n['title']}\në‚´ìš©: {n['text']}" for n in all_news])
                    final_prompt = f"""
                    [ì§€ì¹¨]:
                    - ë°˜ë“œì‹œ ì œê³µëœ [ë‰´ìŠ¤ ë°ì´í„°]ì˜ ë‚´ìš©ë§Œ ë¶„ì„í•˜ë¼.
                    - ë°ì´í„°ê°€ ë¶€ì¡±í•´ë„ ì ˆëŒ€ ë‹¤ë¥¸ ì¢…ëª©(í…ŒìŠ¬ë¼ ë“±)ì„ ëŒì–´ì˜¤ì§€ ë§ˆë¼.
                    - ì˜¤ì§ [ë§íˆ¬ ê°€ì´ë“œ]ì˜ ë¬¸ì²´(í†¤, í˜•ì‹)ë§Œ ê°€ì ¸ì™€ì„œ ì¹œì ˆí•˜ê²Œ ì‘ì„±í•˜ë¼.

                    [ë‰´ìŠ¤ ë°ì´í„°]:
                    {context}
                    
                    [ë§íˆ¬ ê°€ì´ë“œ]:
                    {style_content}
                    """
                    response = model.generate_content(final_prompt)
                    
                    st.divider()
                    st.subheader("âœ… ë¨¸ìŠ¤í¬ë…¸ë¯¸ ë© ë¶„ì„ ê²°ê³¼")
                    st.code(response.text, language='text')
                    st.balloons()
        except Exception as e:
            st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
